# 贝叶斯定理
`w`是由待测数据的所有属性组成的向量。`p(c|x)`表示，在数据为x时，属于c类的概率。
$$
p(c|w)=\frac{p(w|c)p(c)}{p(w)}
$$

如果数据的目标变量最后有两个结果，则需要分别计算`p(c1|x)`和`p(c2|x)`取最大的值为分类的结果
$$
p(c_{1}|w)=\frac{p(w|c_{1})p(c_{1})}{p(w)}、
p(c_{2}|w)=\frac{p(w|c_{2})p(c_{2})}{p(w)}
$$
算法的目的就在于找到最大的 $c_{i}$ 。由于只需要比较两个概率的大小，则分母`p(w)`可以不用算，并不影响结果。那 $p(w|c_{1})p(c_{1})$ 又如何计算呢？一条数据w其实包含很多属性`w=w1,w2,w3,...,wn`.以$p(w|c_{0})p(c_{0})$为例:

`p(c0)` 表示分类结果为`c0`的概率:
$$
p(c_{0})=\frac{数据集中属于c_{0}类别的数据条数}{数据集的总数}
$$

而$p(w|c_{0})$ == $p(w_{1},w_{2},w_{3},...,w_{n}|c_{0})$。朴素贝叶斯分类假设所有属性之间是独立的，互不影响。那么就满足如下关系：
$$
p(w_{1},w_{2},w_{3},...,w_{n}|c_{0}) = p(w_{1}|c{0})p(w_{2}|c{0})p(w_{3}|c{0})...p(w_{n}|c{0}) 
$$ $$
p(w_{1}|c{0})=\frac{在c_{0}类别的数据中出现w1属性的数据条数}{属于c_{0}类别的条数}
$$

至此，已经计算出了足够数据来计算出$p(w|c_{1})p(c_{1})$，用这些概率可以给新的数据分类。如果此时有数据 `w=w1,w3,w5`，那需要分别算出两个分类下的概率：
$$
p(c_{0}|w_{1},w_{3},w_{5})=p(w_{1}|c{0})p(w_{3}|c{0})p(w_{5}|c{0})p(c_{0})
$$ $$
p(c_{1}|w_{1},w_{3},w_{5})=p(w_{1}|c{1})p(w_{3}|c{0})p(w_{5}|c{1})p(c_{1})
$$
比较大小，找到最大的概率，最大概率的$c_{i}$就是分类的结果

